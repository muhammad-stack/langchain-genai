{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import TypedDict\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage  , AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START , StateGraph  , END\n",
    "from langgraph.graph.state import CompiledStateGraph #type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(TypedDict):\n",
    "    prompt : list[str]\n",
    "\n",
    "llm : ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\",api_key=\"AIzaSyAN58kFwDemQk53FZ0C-ON1fYSKIff5AAc\",temperature=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that calls the model\n",
    "def node_1(state: State)  :\n",
    "    response = llm.invoke(state[\"prompt\"])\n",
    "    return {\"messages\": state[\"prompt\"] + response }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f7b6212d430>\n",
       "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'node_1': Node(id='node_1', name='node_1', data=node_1(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='node_1', data=None, conditional=False), Edge(source='node_1', target='__end__', data=None, conditional=False)])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "builder : StateGraph = StateGraph(state_schema=State)\n",
    "\n",
    "# Nodes\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Edges\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph: CompiledStateGraph = builder.compile()\n",
    "print(graph)\n",
    "\n",
    "print(graph.get_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/root/.vscode-server/extensions/ms-python.python-2024.16.1-linux-x64/python_files/python_server.py\", line 130, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 1, in <module>\n",
       "ModuleNotFoundError: No module named 'IPython'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display # Preview Graph\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
